{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b835cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# from torchdiffeq import odeint_adjoint as odeint # We'll use this later\n",
    "\n",
    "# --- 1. The Control Head MLP ---\n",
    "# Predicts explicit parameters (bounding box, number of points) from the latent vector z.\n",
    "class ControlHead(nn.Module):\n",
    "    \"\"\"\n",
    "    An MLP that maps a latent vector z to structural parameters for a 2D slice.\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim: int, hidden_dim: int = 128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            # Output: 4 for bbox (min_x, max_x, min_y, max_y) + 1 for N\n",
    "            nn.Linear(hidden_dim, 5)\n",
    "        )\n",
    "        # Use Softplus to ensure the predicted number of points is always positive.\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, z: torch.Tensor) -> dict:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            z (torch.Tensor): Latent vector, shape (B, latent_dim).\n",
    "        \n",
    "        Returns:\n",
    "            dict: A dictionary containing the predicted bounding box and number of points.\n",
    "        \"\"\"\n",
    "        params = self.net(z)\n",
    "        \n",
    "        # Bbox logits are returned directly. They can be scaled/activated later.\n",
    "        bbox = params[..., :4]\n",
    "        \n",
    "        # Predict N, ensuring it's a positive value. We add a minimum\n",
    "        # value to prevent the model from predicting zero points.\n",
    "        pred_N_logits = params[..., 4]\n",
    "        pred_N = self.softplus(pred_N_logits).round().long() + 1\n",
    "        \n",
    "        return {\n",
    "            \"bbox\": bbox,       # Shape: (B, 4)\n",
    "            \"pred_N\": pred_N,   # Shape: (B,)\n",
    "        }\n",
    "\n",
    "# --- 2. The Generative Core CNF (Skeleton) ---\n",
    "# This is where the Continuous Normalizing Flow will live.\n",
    "class GenerativeCore(nn.Module):\n",
    "    \"\"\"\n",
    "    A placeholder for the CNF that generates a point cloud in a normalized space,\n",
    "    conditioned on the latent vector z.\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim: int, hidden_dim: int = 256):\n",
    "        super().__init__()\n",
    "        # This network represents the core dynamics of the ODE, f(x, t; z).\n",
    "        # In the final version, this will be a more sophisticated network,\n",
    "        # possibly a series of concatenated feed-forward layers.\n",
    "        self.dynamics_net = nn.Sequential(\n",
    "            nn.Linear(2 + latent_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 2) # Output: velocity (dx/dt, dy/dt)\n",
    "        )\n",
    "\n",
    "    def forward(self, z: torch.Tensor, num_points: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            z (torch.Tensor): Latent vector, shape (B, latent_dim).\n",
    "            num_points (int): The number of points to generate for each shape in the batch.\n",
    "        \n",
    "        Returns:\n",
    "            tuple:\n",
    "                - torch.Tensor: Generated points in normalized space, shape (B, N, 2).\n",
    "                - torch.Tensor: The log-likelihood of the generation, shape (B,).\n",
    "        \"\"\"\n",
    "        # --- This is a placeholder implementation ---\n",
    "        # The real implementation will use torchdiffeq.\n",
    "        \n",
    "        # 1. Sample from a base distribution (e.g., N(0,I)).\n",
    "        batch_size = z.shape[0]\n",
    "        base_dist_samples = torch.randn(batch_size, num_points, 2, device=z.device)\n",
    "\n",
    "        # 2. In the final version, you would integrate the dynamics_net from t=0 to t=1\n",
    "        #    using `odeint`. `odeint` would also compute the log-likelihood via the\n",
    "        #    Hutchinson's trace estimator trick.\n",
    "        \n",
    "        # Placeholder for generated points:\n",
    "        # We'll simulate the flow by passing the noise and latent vector through the dynamics net.\n",
    "        # This is NOT a flow, just a stand-in to ensure the architecture connects.\n",
    "        z_expanded = z.unsqueeze(1).expand(-1, num_points, -1)\n",
    "        flow_input = torch.cat([base_dist_samples, z_expanded], dim=-1)\n",
    "        generated_points = torch.tanh(self.dynamics_net(flow_input)) # tanh to keep in [-1, 1]\n",
    "        \n",
    "        # Placeholder for the exact log-likelihood from the CNF.\n",
    "        log_likelihood = torch.zeros(batch_size, device=z.device)\n",
    "\n",
    "        return generated_points, log_likelihood\n",
    "\n",
    "# --- 3. The Main Hybrid Decoder ---\n",
    "# This class orchestrates the ControlHead and the GenerativeCore.\n",
    "class HybridDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    The main decoder module for the 2D Slice VAE.\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim: int, control_hidden_dim: int = 128, cnf_hidden_dim: int = 256):\n",
    "        super().__init__()\n",
    "        self.control_head = ControlHead(latent_dim, control_hidden_dim)\n",
    "        self.generative_core = GenerativeCore(latent_dim, cnf_hidden_dim)\n",
    "\n",
    "    def denormalize(self, points: torch.Tensor, bbox: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Rescales points from the normalized space [-1, 1] to the predicted bounding box.\n",
    "        \n",
    "        Args:\n",
    "            points (torch.Tensor): Points in normalized space, shape (B, N, 2).\n",
    "            bbox (torch.Tensor): Predicted bounding boxes, shape (B, 4).\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Points in the original coordinate space.\n",
    "        \"\"\"\n",
    "        min_x, max_x, min_y, max_y = bbox.chunk(4, dim=-1)\n",
    "        \n",
    "        center_x = (max_x + min_x) / 2\n",
    "        center_y = (max_y + min_y) / 2\n",
    "        scale_x = (max_x - min_x) / 2\n",
    "        scale_y = (max_y - min_y) / 2\n",
    "\n",
    "        points_x = points[..., 0] * scale_x.unsqueeze(-1) + center_x.unsqueeze(-1)\n",
    "        points_y = points[..., 1] * scale_y.unsqueeze(-1) + center_y.unsqueeze(-1)\n",
    "        \n",
    "        return torch.stack([points_x, points_y], dim=-1)\n",
    "\n",
    "    def forward(self, z: torch.Tensor, target_N: int = None) -> dict:\n",
    "        \"\"\"\n",
    "        The main forward pass for decoding a latent vector into a point cloud.\n",
    "        \n",
    "        Args:\n",
    "            z (torch.Tensor): The latent vector, shape (B, latent_dim).\n",
    "            target_N (int, optional): The ground-truth number of points for teacher forcing\n",
    "                                      during training. Defaults to None.\n",
    "        \n",
    "        Returns:\n",
    "            dict: A dictionary containing the final point cloud and other relevant tensors.\n",
    "        \"\"\"\n",
    "        # 1. Predict structural parameters from the latent vector.\n",
    "        control_params = self.control_head(z)\n",
    "        bbox = control_params[\"bbox\"]\n",
    "        \n",
    "        # During training, we can use the ground-truth N (teacher forcing).\n",
    "        # During inference, we must use the predicted N.\n",
    "        # For this skeleton, we assume a single value for the batch.\n",
    "        num_points_to_gen = target_N if target_N is not None else control_params[\"pred_N\"][0].item()\n",
    "\n",
    "        # 2. Generate points in normalized space using the CNF core.\n",
    "        normalized_points, log_likelihood = self.generative_core(z, num_points_to_gen)\n",
    "        \n",
    "        # 3. De-normalize the points to fit the predicted bounding box.\n",
    "        denormalized_points = self.denormalize(normalized_points, bbox)\n",
    "\n",
    "        return {\n",
    "            \"points\": denormalized_points,      # The final generated point cloud\n",
    "            \"log_likelihood\": log_likelihood,    # For the reconstruction loss\n",
    "            \"bbox\": bbox,                        # The predicted bounding box\n",
    "            \"pred_N\": control_params[\"pred_N\"]   # The predicted number of points\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c06648ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limiting dataset to the first 10 files.\n",
      "Loading data from 10 files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 351.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully created a small dataset with a total of 800 slices.\n",
      "\n",
      "--- Correctly Formatted PyG Batch from SMALL .npy SUBSET ---\n",
      "DataBatch(x=[46217, 2], batch=[46217], ptr=[33])\n",
      "\n",
      "Total number of slices in this batch: 32\n",
      "Total number of points in all slices in this batch: 46217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "class SlicesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset that loads slices from a LIMITED number of raw .npy files.\n",
    "    This is memory-efficient and points to the correct raw data source.\n",
    "    \"\"\"\n",
    "    def __init__(self, npy_dir, limit_files=None):\n",
    "        self.slices = []\n",
    "        \n",
    "        file_list = sorted([f for f in os.listdir(npy_dir) if f.endswith('.npy')])\n",
    "        if limit_files is not None:\n",
    "            print(f\"Limiting dataset to the first {limit_files} files.\")\n",
    "            file_list = file_list[:limit_files]\n",
    "        \n",
    "        print(f\"Loading data from {len(file_list)} files...\")\n",
    "        for file_name in tqdm(file_list):\n",
    "            file_path = os.path.join(npy_dir, file_name)\n",
    "            try:\n",
    "                # Load the list of slice arrays from the .npy file\n",
    "                all_slice_arrays = np.load(file_path, allow_pickle=True)\n",
    "                for point_array in all_slice_arrays:\n",
    "                    if point_array.shape[0] > 0:\n",
    "                        self.slices.append(Data(x=torch.from_numpy(point_array).float()))\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping corrupted file {file_name}: {e}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.slices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.slices[idx]\n",
    "\n",
    "# --- Setup the DataLoader with a small, manageable subset ---\n",
    "# CORRECTED: Pointing to the raw slices directory\n",
    "DATA_DIR = \"../../outputs/slices/\" \n",
    "NUM_FILES_TO_TRAIN_ON = 10 # Start with just 10 cars\n",
    "\n",
    "try:\n",
    "    poc_dataset = SlicesDataset(npy_dir=DATA_DIR, limit_files=NUM_FILES_TO_TRAIN_ON)\n",
    "    print(f\"\\nSuccessfully created a small dataset with a total of {len(poc_dataset)} slices.\")\n",
    "\n",
    "    # We'll use a batch size of 32 slices for training\n",
    "    poc_dataloader = DataLoader(poc_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # --- Test the new DataLoader ---\n",
    "    first_poc_batch = next(iter(poc_dataloader))\n",
    "\n",
    "    print(\"\\n--- Correctly Formatted PyG Batch from SMALL .npy SUBSET ---\")\n",
    "    print(first_poc_batch)\n",
    "    print(f\"\\nTotal number of slices in this batch: {first_poc_batch.num_graphs}\")\n",
    "    print(f\"Total number of points in all slices in this batch: {first_poc_batch.num_nodes}\")\n",
    "\n",
    "except (IOError, FileNotFoundError) as e:\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce76b690",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SingleFileNpyDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m test_file_path = os.path.join(DATA_DIR, TEST_FILE_NAME)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# THE FIX: Removed the keyword 'file_path='\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     single_file_dataset = \u001b[43mSingleFileNpyDataset\u001b[49m(test_file_path)\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# Batch size > number of slices to get all slices from our one car at once\u001b[39;00m\n\u001b[32m     11\u001b[39m     single_file_dataloader = DataLoader(single_file_dataset, batch_size=\u001b[32m100\u001b[39m) \n",
      "\u001b[31mNameError\u001b[39m: name 'SingleFileNpyDataset' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Setup for our single test file ---\n",
    "DATA_DIR = \"../../outputs/slices/\"\n",
    "TEST_FILE_NAME = \"DrivAer_F_D_WM_WW_0001_axis-x.npy\"\n",
    "test_file_path = os.path.join(DATA_DIR, TEST_FILE_NAME)\n",
    "\n",
    "try:\n",
    "    # THE FIX: Removed the keyword 'file_path='\n",
    "    single_file_dataset = SingleFileNpyDataset(test_file_path)\n",
    "    \n",
    "    # Batch size > number of slices to get all slices from our one car at once\n",
    "    single_file_dataloader = DataLoader(single_file_dataset, batch_size=100) \n",
    "\n",
    "    # --- Run the Test ---\n",
    "    single_car_batch = next(iter(single_file_dataloader))\n",
    "\n",
    "    print(\"\\n--- Correctly Formatted PyG Batch from SINGLE .npy FILE ---\")\n",
    "    print(single_car_batch)\n",
    "    print(f\"\\nTotal number of slices in this batch: {single_car_batch.num_graphs}\")\n",
    "    print(f\"Total number of points in all slices in this batch: {single_car_batch.num_nodes}\")\n",
    "\n",
    "except (IOError, FileNotFoundError) as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e4639dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized PyG-based Encoder architecture defined.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import EdgeConv, knn_graph, global_max_pool\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "class DGCNN_VAE_Encoder_PyG(nn.Module):\n",
    "    \"\"\"\n",
    "    The final, optimized VAE Encoder for 2D slices using PyTorch Geometric.\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim=128, k=20):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # Layer 1: Takes 2D points -> 64-dim features\n",
    "        self.conv1 = EdgeConv(\n",
    "            nn=nn.Sequential(\n",
    "                nn.Linear(2 * 2, 64),\n",
    "                nn.LeakyReLU(0.2),\n",
    "            ),\n",
    "            aggr=\"max\"\n",
    "        )\n",
    "\n",
    "        # Layer 2: Takes 64-dim features -> 128-dim features\n",
    "        self.conv2 = EdgeConv(\n",
    "            nn=nn.Sequential(\n",
    "                nn.Linear(2 * 64, 128),\n",
    "                nn.LeakyReLU(0.2),\n",
    "            ),\n",
    "            aggr=\"max\"\n",
    "        )\n",
    "        \n",
    "        # Global feature aggregator\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 + 128, 1024),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Linear(1024, 256)\n",
    "        )\n",
    "        \n",
    "        # VAE output layers for mu and log_var\n",
    "        self.fc_mu = nn.Linear(256, latent_dim)\n",
    "        self.fc_log_var = nn.Linear(256, latent_dim)\n",
    "\n",
    "    def forward(self, data: Batch) -> (torch.Tensor, torch.Tensor):\n",
    "        # data.x contains all points from all slices, shape: [total_points, 2]\n",
    "        # data.batch contains the slice index for each point, shape: [total_points]\n",
    "\n",
    "        # --- Layer 1 ---\n",
    "        edge_index1 = knn_graph(data.x, k=self.k, batch=data.batch)\n",
    "        h1 = self.conv1(data.x, edge_index1)\n",
    "\n",
    "        # --- Layer 2 (Dynamic Graph) ---\n",
    "        # Build the new graph on the FEATURES from Layer 1\n",
    "        edge_index2 = knn_graph(h1, k=self.k, batch=data.batch)\n",
    "        h2 = self.conv2(h1, edge_index2)\n",
    "\n",
    "        # --- Aggregate Features ---\n",
    "        h_combined = torch.cat([h1, h2], dim=1)\n",
    "        global_feature = global_max_pool(h_combined, data.batch)\n",
    "        \n",
    "        # --- Final Layers ---\n",
    "        global_feature = self.fc(global_feature)\n",
    "        mu = self.fc_mu(global_feature)\n",
    "        log_var = self.fc_log_var(global_feature)\n",
    "        \n",
    "        return mu, log_var\n",
    "\n",
    "print(\"Optimized PyG-based Encoder architecture defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "216b08b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input was a batch with 80 slices.\n",
      "\n",
      "--- Output Shapes ---\n",
      "  - mu vector shape: torch.Size([80, 128])\n",
      "  - log_var vector shape: torch.Size([80, 128])\n",
      "\n",
      "--- Example Output Values (mu, first 5 slices) ---\n",
      "tensor([[ 3.7364e-02,  2.9910e-02,  5.0200e-02, -3.1608e-02, -7.5958e-02,\n",
      "          3.4142e-02,  2.7590e-02, -6.1911e-02, -1.8707e-02, -8.9737e-02,\n",
      "         -2.2632e-03, -7.4745e-02,  2.5395e-02, -2.4939e-02, -2.5143e-02,\n",
      "          1.4177e-02,  6.1716e-02,  3.0645e-03, -2.8931e-02,  3.4949e-02,\n",
      "         -1.1050e-02, -5.4430e-02,  3.1064e-03,  3.5054e-02, -7.9312e-02,\n",
      "         -4.1653e-02, -6.8330e-02, -1.0872e-02,  4.7025e-02,  3.4532e-02,\n",
      "          3.6045e-02,  6.1124e-02,  5.3892e-02,  5.0488e-02,  6.3993e-02,\n",
      "         -3.8044e-02,  8.8524e-02,  3.7512e-02,  3.8550e-02, -9.3991e-03,\n",
      "          6.4512e-04,  6.6446e-02, -6.8560e-02,  9.4123e-03, -5.0288e-02,\n",
      "         -3.0981e-03, -1.8068e-02,  4.5526e-02, -1.1319e-03,  1.1359e-02,\n",
      "          1.4685e-02, -5.1980e-02, -4.0908e-02, -3.6909e-02,  1.4114e-02,\n",
      "         -2.1747e-02, -5.8674e-03,  8.8599e-02,  2.3593e-02, -7.6477e-02,\n",
      "         -1.2455e-02,  8.4443e-03, -5.4342e-02,  7.4049e-02,  6.8646e-02,\n",
      "          1.4747e-02,  5.5830e-02, -3.0377e-02, -3.0162e-02, -8.7689e-02,\n",
      "          2.2377e-02,  1.1597e-02, -2.5636e-02,  7.4844e-03, -7.4908e-02,\n",
      "          6.0497e-02, -6.8058e-02, -4.2392e-02,  5.4702e-02, -1.0627e-02,\n",
      "          6.9408e-02,  8.6140e-03,  9.6128e-03,  2.7080e-02, -4.0360e-02,\n",
      "         -3.9307e-02,  5.7581e-02,  9.3497e-02,  9.1054e-02, -5.5256e-02,\n",
      "         -9.5198e-02, -3.0208e-02, -6.0769e-02, -9.8762e-02,  4.1380e-02,\n",
      "          5.2528e-02, -2.2510e-02, -2.5832e-02, -1.4829e-02,  6.5724e-03,\n",
      "          1.0125e-02, -5.3836e-02, -6.1514e-02,  1.3658e-02,  1.3568e-02,\n",
      "          1.2552e-01,  1.6912e-02,  4.6553e-02,  4.8979e-02, -2.8795e-02,\n",
      "          3.5082e-02, -3.6713e-03,  1.6470e-03,  5.6424e-03,  5.2517e-02,\n",
      "         -1.6625e-02,  8.7452e-03,  4.3331e-02, -3.1247e-02,  2.3310e-03,\n",
      "          8.3472e-03,  9.4264e-02, -7.9372e-02,  1.2059e-01, -5.4146e-02,\n",
      "         -3.5809e-03, -1.3679e-02, -1.4938e-02],\n",
      "        [ 3.6880e-02,  3.0465e-02,  4.9310e-02, -2.9828e-02, -7.5543e-02,\n",
      "          3.1680e-02,  2.9906e-02, -6.5472e-02, -1.5495e-02, -8.9951e-02,\n",
      "          3.3516e-03, -7.7487e-02,  2.3881e-02, -3.0396e-02, -2.1079e-02,\n",
      "          1.3597e-02,  6.4858e-02,  5.0991e-03, -3.0356e-02,  3.7410e-02,\n",
      "         -1.4531e-02, -5.5353e-02,  4.6330e-03,  3.9808e-02, -8.2777e-02,\n",
      "         -4.5609e-02, -7.4376e-02, -1.3306e-02,  5.0104e-02,  3.1353e-02,\n",
      "          3.9480e-02,  6.4296e-02,  5.1040e-02,  4.4937e-02,  6.4430e-02,\n",
      "         -4.1218e-02,  9.0180e-02,  3.8502e-02,  3.4634e-02, -3.7476e-03,\n",
      "          6.2928e-03,  7.1730e-02, -6.9018e-02,  6.9059e-03, -5.5916e-02,\n",
      "          3.7628e-05, -1.2381e-02,  4.3321e-02,  3.6479e-03,  1.2973e-02,\n",
      "          1.8083e-02, -5.5817e-02, -4.5792e-02, -3.8062e-02,  1.7734e-02,\n",
      "         -1.9704e-02, -6.5184e-03,  9.3897e-02,  2.8570e-02, -8.2513e-02,\n",
      "         -1.3364e-02,  3.7721e-03, -5.5944e-02,  7.5493e-02,  6.8075e-02,\n",
      "          1.3036e-02,  6.2550e-02, -2.8029e-02, -3.7841e-02, -8.8073e-02,\n",
      "          2.0737e-02,  1.2107e-02, -3.0295e-02,  9.5924e-03, -8.1669e-02,\n",
      "          5.9599e-02, -7.0378e-02, -4.8313e-02,  5.8743e-02, -1.4430e-02,\n",
      "          7.3115e-02,  8.7089e-03,  1.1911e-02,  2.9460e-02, -3.9563e-02,\n",
      "         -4.1179e-02,  5.7266e-02,  9.7786e-02,  9.5182e-02, -6.2531e-02,\n",
      "         -9.7285e-02, -2.8559e-02, -6.6904e-02, -1.0474e-01,  4.2562e-02,\n",
      "          5.3139e-02, -2.1828e-02, -2.2401e-02, -1.0794e-02,  9.7686e-03,\n",
      "          1.1825e-02, -5.1510e-02, -5.7494e-02,  1.1483e-02,  1.3326e-02,\n",
      "          1.3039e-01,  2.3667e-02,  4.8732e-02,  5.2290e-02, -2.4787e-02,\n",
      "          3.0531e-02, -2.3183e-03, -6.0385e-04,  2.1878e-03,  5.2949e-02,\n",
      "         -1.7707e-02,  6.7212e-03,  4.4641e-02, -3.3783e-02,  8.5040e-03,\n",
      "          9.0613e-03,  9.7641e-02, -7.9917e-02,  1.2504e-01, -6.0351e-02,\n",
      "         -1.2895e-03, -1.0782e-02, -1.0178e-02],\n",
      "        [ 3.7939e-02,  3.3927e-02,  4.8927e-02, -2.6419e-02, -7.4577e-02,\n",
      "          2.9536e-02,  3.0171e-02, -6.4597e-02, -1.4230e-02, -8.8058e-02,\n",
      "          9.7119e-03, -7.8513e-02,  2.6217e-02, -3.1655e-02, -1.9758e-02,\n",
      "          1.3218e-02,  6.6928e-02,  2.4259e-03, -3.1311e-02,  3.8970e-02,\n",
      "         -1.6695e-02, -5.5301e-02,  5.4726e-03,  4.2420e-02, -8.4455e-02,\n",
      "         -4.5999e-02, -7.4228e-02, -1.6100e-02,  5.0918e-02,  3.2113e-02,\n",
      "          4.2626e-02,  6.3410e-02,  4.7988e-02,  4.1718e-02,  6.3835e-02,\n",
      "         -4.0020e-02,  9.2288e-02,  4.2086e-02,  3.6611e-02, -3.4703e-03,\n",
      "          5.6400e-03,  7.2921e-02, -6.8567e-02,  5.9667e-03, -6.1070e-02,\n",
      "          2.0252e-03, -9.9621e-03,  3.9460e-02,  8.8541e-03,  1.7825e-02,\n",
      "          1.7616e-02, -5.4313e-02, -4.7597e-02, -4.5442e-02,  1.9633e-02,\n",
      "         -1.7778e-02, -5.8387e-03,  9.4843e-02,  2.9592e-02, -8.4273e-02,\n",
      "         -1.5872e-02,  8.0238e-04, -5.7774e-02,  8.0273e-02,  6.6351e-02,\n",
      "          8.3622e-03,  6.2241e-02, -3.0737e-02, -4.0114e-02, -8.9325e-02,\n",
      "          2.0168e-02,  1.5249e-02, -3.1234e-02,  1.1229e-02, -8.5803e-02,\n",
      "          6.0529e-02, -7.1707e-02, -5.5719e-02,  6.2631e-02, -1.7058e-02,\n",
      "          7.4246e-02,  8.1092e-03,  1.3107e-02,  2.8384e-02, -3.5186e-02,\n",
      "         -4.0651e-02,  5.9845e-02,  1.0144e-01,  9.7343e-02, -6.3095e-02,\n",
      "         -9.8956e-02, -2.6130e-02, -7.0657e-02, -1.0646e-01,  4.2392e-02,\n",
      "          5.4471e-02, -2.5669e-02, -2.2512e-02, -9.3142e-03,  8.3809e-03,\n",
      "          1.2121e-02, -5.3852e-02, -5.3673e-02,  1.1005e-02,  1.4780e-02,\n",
      "          1.3310e-01,  2.9663e-02,  5.3229e-02,  5.2658e-02, -2.5242e-02,\n",
      "          2.7177e-02, -9.6819e-04, -2.8493e-04, -1.5347e-03,  5.2753e-02,\n",
      "         -2.0305e-02,  6.4700e-03,  4.8442e-02, -3.8072e-02,  1.0896e-02,\n",
      "          1.0557e-02,  1.0067e-01, -8.0414e-02,  1.2878e-01, -6.0979e-02,\n",
      "          4.7326e-03, -6.0116e-03, -7.3881e-03],\n",
      "        [ 3.8033e-02,  3.1345e-02,  4.8349e-02, -2.2062e-02, -7.4197e-02,\n",
      "          2.9138e-02,  3.2065e-02, -6.4866e-02, -1.5613e-02, -8.6480e-02,\n",
      "          1.5753e-02, -7.9563e-02,  2.5523e-02, -3.6809e-02, -1.7256e-02,\n",
      "          1.4970e-02,  6.9447e-02,  2.4421e-03, -3.0444e-02,  4.0440e-02,\n",
      "         -2.1170e-02, -5.5301e-02,  5.6660e-03,  4.6861e-02, -8.7075e-02,\n",
      "         -4.5936e-02, -7.6165e-02, -2.2258e-02,  5.1154e-02,  3.3721e-02,\n",
      "          4.5237e-02,  6.4338e-02,  4.5771e-02,  3.5736e-02,  6.3915e-02,\n",
      "         -3.9752e-02,  9.3978e-02,  4.3051e-02,  3.4936e-02, -2.2236e-03,\n",
      "          7.7302e-03,  7.6173e-02, -6.9010e-02,  3.8164e-03, -6.5721e-02,\n",
      "          1.4827e-03, -6.9024e-03,  3.6208e-02,  1.2800e-02,  2.1914e-02,\n",
      "          1.7402e-02, -5.6426e-02, -4.8893e-02, -4.9622e-02,  2.3351e-02,\n",
      "         -1.9170e-02, -4.6398e-03,  9.8106e-02,  3.2917e-02, -8.4814e-02,\n",
      "         -1.5804e-02, -3.2130e-03, -5.9656e-02,  8.4076e-02,  6.7267e-02,\n",
      "          5.3789e-03,  6.5406e-02, -3.1740e-02, -4.2763e-02, -9.1349e-02,\n",
      "          2.2898e-02,  1.6860e-02, -3.2432e-02,  8.8838e-03, -9.0231e-02,\n",
      "          6.2464e-02, -7.1124e-02, -6.0986e-02,  6.4355e-02, -2.0290e-02,\n",
      "          7.7716e-02,  8.8912e-03,  1.5285e-02,  3.0006e-02, -3.3380e-02,\n",
      "         -4.1339e-02,  6.1992e-02,  1.0696e-01,  1.0055e-01, -6.4272e-02,\n",
      "         -1.0060e-01, -2.5035e-02, -7.7230e-02, -1.1006e-01,  3.9994e-02,\n",
      "          5.5767e-02, -2.6478e-02, -2.1729e-02, -7.3924e-03,  7.0403e-03,\n",
      "          1.3227e-02, -5.6121e-02, -4.9093e-02,  9.2517e-03,  1.5466e-02,\n",
      "          1.3597e-01,  3.5351e-02,  5.5039e-02,  5.6130e-02, -2.4251e-02,\n",
      "          2.2072e-02,  1.4868e-03, -1.7561e-03, -4.4374e-03,  5.1173e-02,\n",
      "         -2.4475e-02,  4.9695e-03,  5.0747e-02, -4.0964e-02,  1.5662e-02,\n",
      "          1.2459e-02,  1.0476e-01, -8.1430e-02,  1.3410e-01, -6.3321e-02,\n",
      "          4.9295e-03, -2.1587e-03, -5.0778e-03],\n",
      "        [ 3.7785e-02,  3.1320e-02,  4.8219e-02, -2.0136e-02, -7.2588e-02,\n",
      "          2.8463e-02,  3.1877e-02, -6.4579e-02, -1.6636e-02, -8.5176e-02,\n",
      "          2.0844e-02, -8.0663e-02,  2.5705e-02, -4.0142e-02, -1.6881e-02,\n",
      "          1.5186e-02,  7.0958e-02, -2.4508e-05, -3.1278e-02,  4.2949e-02,\n",
      "         -2.2860e-02, -5.6951e-02,  5.9084e-03,  4.9331e-02, -8.8342e-02,\n",
      "         -4.6734e-02, -7.8181e-02, -2.7096e-02,  5.0821e-02,  3.2894e-02,\n",
      "          4.7442e-02,  6.5307e-02,  4.4447e-02,  3.0775e-02,  6.3351e-02,\n",
      "         -3.8700e-02,  9.5955e-02,  4.4158e-02,  3.6407e-02, -1.9497e-03,\n",
      "          8.5494e-03,  7.8859e-02, -6.9821e-02,  2.0754e-03, -7.1271e-02,\n",
      "          2.0786e-03, -5.2366e-03,  3.4671e-02,  1.5798e-02,  2.5754e-02,\n",
      "          1.7694e-02, -5.6218e-02, -4.8559e-02, -5.3442e-02,  2.4980e-02,\n",
      "         -1.9330e-02, -4.1390e-03,  1.0080e-01,  3.4311e-02, -8.6299e-02,\n",
      "         -1.7841e-02, -5.9581e-03, -6.0163e-02,  8.7268e-02,  6.7590e-02,\n",
      "          4.1717e-03,  6.6971e-02, -3.3264e-02, -4.5990e-02, -9.1887e-02,\n",
      "          2.2858e-02,  1.8494e-02, -3.4091e-02,  9.4651e-03, -9.3977e-02,\n",
      "          6.4004e-02, -7.1876e-02, -6.6018e-02,  6.7145e-02, -2.2697e-02,\n",
      "          7.8573e-02,  9.3636e-03,  1.6612e-02,  3.0539e-02, -3.0237e-02,\n",
      "         -4.2087e-02,  6.3731e-02,  1.1015e-01,  1.0285e-01, -6.4656e-02,\n",
      "         -1.0178e-01, -2.4826e-02, -8.0687e-02, -1.1234e-01,  3.8963e-02,\n",
      "          5.5945e-02, -2.7359e-02, -2.2017e-02, -7.3080e-03,  5.9745e-03,\n",
      "          1.4103e-02, -5.6974e-02, -4.4559e-02,  8.9370e-03,  1.5989e-02,\n",
      "          1.3829e-01,  3.9896e-02,  5.7867e-02,  5.6260e-02, -2.3265e-02,\n",
      "          1.9181e-02,  4.2272e-03, -1.9602e-03, -7.8268e-03,  5.0665e-02,\n",
      "         -2.5723e-02,  5.1238e-03,  5.1697e-02, -4.4081e-02,  1.7515e-02,\n",
      "          1.5714e-02,  1.0790e-01, -8.1691e-02,  1.3745e-01, -6.5012e-02,\n",
      "          6.0209e-03, -4.3997e-04, -2.3269e-03]])\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Set up the model and device ---\n",
    "LATENT_DIM = 128\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create an instance of our encoder and move it to the correct device\n",
    "encoder = DGCNN_VAE_Encoder_PyG(latent_dim=LATENT_DIM, k=20).to(DEVICE)\n",
    "encoder.eval() # Set the model to evaluation mode for this test\n",
    "\n",
    "# --- 2. Move the data to the correct device ---\n",
    "# The 'single_car_batch' is from Notebook Cell 2\n",
    "batch_on_device = single_car_batch.to(DEVICE)\n",
    "\n",
    "# --- 3. Pass the batch through the encoder ---\n",
    "with torch.no_grad():\n",
    "    mu, log_var = encoder(batch_on_device)\n",
    "\n",
    "# --- 4. Check the results ---\n",
    "print(f\"Input was a batch with {batch_on_device.num_graphs} slices.\")\n",
    "print(\"\\n--- Output Shapes ---\")\n",
    "print(f\"  - mu vector shape: {mu.shape}\")\n",
    "print(f\"  - log_var vector shape: {log_var.shape}\")\n",
    "\n",
    "# --- 5. Sanity check the values ---\n",
    "print(\"\\n--- Example Output Values (mu, first 5 slices) ---\")\n",
    "print(mu[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "72fd844c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ControlHead module defined.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ControlHead(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple MLP that predicts the 'scaffolding' for a 2D slice from a latent vector.\n",
    "    - A 4-value bounding box (min_x, max_x, min_y, max_y)\n",
    "    - A 1-value estimated point count (N)\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim=128, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # We output 5 continuous values\n",
    "            nn.Linear(hidden_dim, 5) \n",
    "        )\n",
    "        # Use softplus activation for the point count to ensure it's always positive\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, z):\n",
    "        # z has shape (batch_size, latent_dim)\n",
    "        params = self.mlp(z)\n",
    "        \n",
    "        # The first 4 values are for the bounding box\n",
    "        bbox = params[:, :4]\n",
    "        \n",
    "        # The 5th value is for the point count N. We apply softplus to ensure N > 0.\n",
    "        # We add 1 to avoid predicting N=0, which can cause issues.\n",
    "        n_points = self.softplus(params[:, 4].unsqueeze(1)) + 1\n",
    "        \n",
    "        return bbox, n_points\n",
    "\n",
    "print(\"ControlHead module defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "902769d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input z shape: torch.Size([80, 128])\n",
      "\n",
      "--- Output Shapes ---\n",
      "  - Predicted bbox shape: torch.Size([80, 4])\n",
      "  - Predicted N points shape: torch.Size([80, 1])\n",
      "\n",
      "--- Example Output Values (first 5 slices) ---\n",
      "BBox [min_x, max_x, min_y, max_y]:\n",
      "tensor([[-0.0524, -0.0039, -0.0465, -0.0084],\n",
      "        [-0.0527, -0.0036, -0.0468, -0.0085],\n",
      "        [-0.0526, -0.0031, -0.0470, -0.0087],\n",
      "        [-0.0526, -0.0026, -0.0473, -0.0089],\n",
      "        [-0.0526, -0.0022, -0.0473, -0.0090]])\n",
      "\n",
      "N Points (estimated):\n",
      "tensor([[1.6926],\n",
      "        [1.6928],\n",
      "        [1.6927],\n",
      "        [1.6926],\n",
      "        [1.6926]])\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Set up the model and device ---\n",
    "# This must match the latent_dim of our encoder\n",
    "LATENT_DIM = 128\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "control_head = ControlHead(latent_dim=LATENT_DIM).to(DEVICE)\n",
    "control_head.eval()\n",
    "\n",
    "# --- 2. Use the 'mu' tensor from the previous cell as our test input z ---\n",
    "# 'mu' is already on the correct device if the previous cell ran successfully\n",
    "# mu has shape [80, 128]\n",
    "test_z = mu \n",
    "\n",
    "# --- 3. Pass the batch through the control head ---\n",
    "with torch.no_grad():\n",
    "    predicted_bbox, predicted_n_points = control_head(test_z)\n",
    "\n",
    "# --- 4. Check the results ---\n",
    "print(f\"Input z shape: {test_z.shape}\")\n",
    "print(\"\\n--- Output Shapes ---\")\n",
    "print(f\"  - Predicted bbox shape: {predicted_bbox.shape}\")\n",
    "print(f\"  - Predicted N points shape: {predicted_n_points.shape}\")\n",
    "\n",
    "# --- 5. Sanity check the values ---\n",
    "print(\"\\n--- Example Output Values (first 5 slices) ---\")\n",
    "print(\"BBox [min_x, max_x, min_y, max_y]:\")\n",
    "print(predicted_bbox[:5])\n",
    "print(\"\\nN Points (estimated):\")\n",
    "print(predicted_n_points[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42d371c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerativeCore module defined (Corrected).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "\n",
    "class ODEFunc(nn.Module):\n",
    "    \"\"\"The neural network that defines the 'wind map'. Now accepts z in forward pass.\"\"\"\n",
    "    def __init__(self, latent_dim=128, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        # The network now takes a concatenated (point_coords, z) as input directly\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2 + latent_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, t, y_and_z):\n",
    "        # y_and_z is a tuple: (point_positions, latent_vector)\n",
    "        y, z = y_and_z\n",
    "        \n",
    "        # Expand z to match the number of points\n",
    "        z_expanded = z.unsqueeze(1).expand(-1, y.shape[1], -1)\n",
    "        \n",
    "        # Concatenate each point's position with the shared latent vector\n",
    "        nn_input = torch.cat([y, z_expanded], dim=2)\n",
    "        \n",
    "        # The output of the network is the 'wind' for the points (dy/dt)\n",
    "        # The 'wind' for z is zero, as it's a constant throughout the integration\n",
    "        zero_for_z = torch.zeros_like(z)\n",
    "\n",
    "        return (self.net(nn_input), zero_for_z)\n",
    "\n",
    "class GenerativeCore(nn.Module):\n",
    "    \"\"\"The 'Sculptor' module that generates points using a Continuous Normalizing Flow.\"\"\"\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super().__init__()\n",
    "        self.ode_func = ODEFunc(latent_dim=latent_dim)\n",
    "        self.integration_times = torch.tensor([0.0, 1.0])\n",
    "\n",
    "    def generate(self, z, num_points):\n",
    "        \"\"\"The FORWARD 'blob-to-slice' pass (for generation).\"\"\"\n",
    "        blob = torch.randn(z.shape[0], num_points, 2).to(z.device)\n",
    "        \n",
    "        # We now pass a tuple (initial_points, z) to the solver.\n",
    "        # z will be passed through the ODE solver but its gradient will be zero.\n",
    "        initial_state = (blob, z)\n",
    "        self.integration_times = self.integration_times.to(z.device)\n",
    "        \n",
    "        solution_y, _ = odeint(self.ode_func, initial_state, self.integration_times, method='dopri5')\n",
    "        \n",
    "        return solution_y[1] # Return the point positions at t=1\n",
    "\n",
    "    def get_log_likelihood(self, slice_points, z):\n",
    "        \"\"\"The REVERSE 'slice-to-blob' pass (for training).\"\"\"\n",
    "        initial_state = (slice_points, z)\n",
    "        self.integration_times = self.integration_times.to(z.device)\n",
    "        \n",
    "        reverse_solution_y, _ = odeint(self.ode_func, initial_state, self.integration_times.flip(0), method='dopri5')\n",
    "        \n",
    "        blob_points = reverse_solution_y[1]\n",
    "\n",
    "        log_p_blob = torch.distributions.Normal(0, 1).log_prob(blob_points).sum(dim=[1, 2])\n",
    "        \n",
    "        return log_p_blob\n",
    "\n",
    "print(\"GenerativeCore module defined (Corrected).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7888e99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Forward Pass Test (Generation) ---\n",
      "Input z shape: torch.Size([4, 128])\n",
      "Number of points to generate: 500\n",
      "Output points shape: torch.Size([4, 500, 2])\n",
      "\n",
      "--- Reverse Pass Test (Log Likelihood) ---\n",
      "Input points shape: torch.Size([4, 500, 2])\n",
      "Input z shape: torch.Size([4, 128])\n",
      "Output log_likelihood shape: torch.Size([4])\n",
      "Example log_likelihood values: [-1381.3058 -1443.263  -1412.0374 -1405.3706]\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Set up the models and device ---\n",
    "LATENT_DIM = 128\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "generative_core = GenerativeCore(latent_dim=LATENT_DIM).to(DEVICE)\n",
    "generative_core.eval()\n",
    "\n",
    "# --- 2. Create some dummy data ---\n",
    "batch_size = 4\n",
    "num_points_to_generate = 500\n",
    "test_z = torch.randn(batch_size, LATENT_DIM).to(DEVICE)\n",
    "\n",
    "# --- 3. Test the FORWARD pass (generation) ---\n",
    "with torch.no_grad():\n",
    "    generated_points = generative_core.generate(test_z, num_points_to_generate)\n",
    "print(\"--- Forward Pass Test (Generation) ---\")\n",
    "print(f\"Input z shape: {test_z.shape}\")\n",
    "print(f\"Number of points to generate: {num_points_to_generate}\")\n",
    "print(f\"Output points shape: {generated_points.shape}\") # Should be [4, 500, 2]\n",
    "\n",
    "# --- 4. Test the REVERSE pass (log likelihood) ---\n",
    "with torch.no_grad():\n",
    "    log_likelihood = generative_core.get_log_likelihood(generated_points, test_z)\n",
    "print(\"\\n--- Reverse Pass Test (Log Likelihood) ---\")\n",
    "print(f\"Input points shape: {generated_points.shape}\")\n",
    "print(f\"Input z shape: {test_z.shape}\")\n",
    "print(f\"Output log_likelihood shape: {log_likelihood.shape}\") # Should be [4]\n",
    "print(f\"Example log_likelihood values: {log_likelihood.cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "03493ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. Set up the model and device (as before) ---\n",
    "LATENT_DIM = 128\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "generative_core = GenerativeCore(latent_dim=LATENT_DIM).to(DEVICE)\n",
    "generative_core.eval()\n",
    "\n",
    "# --- 2. Create a single random latent vector ---\n",
    "# We'll generate one slice for this visualization\n",
    "test_z = torch.randn(1, LATENT_DIM).to(DEVICE)\n",
    "num_points = 2000 # Let's generate a decent number of points\n",
    "\n",
    "# --- 3. Generate the 2D point cloud ---\n",
    "with torch.no_grad():\n",
    "    generated_points = generative_core.generate(test_z, num_points)\n",
    "\n",
    "# --- 4. Plot the result ---\n",
    "# Move points to the CPU and convert to a numpy array for plotting\n",
    "points_np = generated_points.squeeze(0).cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(points_np[:, 0], points_np[:, 1], s=1) # s=1 makes the points small\n",
    "plt.title(\"Sanity Check: Output of Untrained Generative Core\")\n",
    "plt.xlabel(\"X coordinate\")\n",
    "plt.ylabel(\"Y coordinate\")\n",
    "plt.axis('equal')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7272ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete SliceVAE model defined.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "# We assume the modules from the previous cells are defined:\n",
    "# - DGCNN_VAE_Encoder_PyG\n",
    "# - ControlHead\n",
    "# - GenerativeCore\n",
    "\n",
    "class SliceVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    The complete Variational Autoencoder for 2D slices.\n",
    "    Combines the Encoder and the Hybrid Decoder (ControlHead + GenerativeCore).\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim=128, k=20):\n",
    "        super().__init__()\n",
    "        self.encoder = DGCNN_VAE_Encoder_PyG(latent_dim=latent_dim, k=k)\n",
    "        self.control_head = ControlHead(latent_dim=latent_dim)\n",
    "        self.generative_core = GenerativeCore(latent_dim=latent_dim)\n",
    "        \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"Standard VAE reparameterization trick.\"\"\"\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, data: Batch):\n",
    "        # Encode the batch of slices to get latent distributions\n",
    "        mu, log_var = self.encoder(data)\n",
    "        \n",
    "        # Sample from the latent distributions to get z\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        \n",
    "        # The decoder uses z to predict the scaffolding and generate the shape\n",
    "        predicted_bbox, predicted_n = self.control_head(z)\n",
    "        \n",
    "        # For this forward pass, we return everything needed to calculate the loss\n",
    "        return mu, log_var, z, predicted_bbox, predicted_n\n",
    "\n",
    "    def loss_function(self, data: Batch, mu, log_var, z, predicted_bbox, predicted_n):\n",
    "        # --- 1. Reconstruction Loss (from Generative Core) ---\n",
    "        # The decoder needs to reconstruct each slice in the batch.\n",
    "        # We process each slice's points individually.\n",
    "        \n",
    "        # First, we need to \"unbatch\" the data from the PyG Batch object\n",
    "        slice_points_list = [data.x[data.batch == i] for i in range(data.num_graphs)]\n",
    "        \n",
    "        # The Generative Core needs the points to have a batch dimension for its ODE solver\n",
    "        # We'll process one slice at a time for simplicity in the loss calculation\n",
    "        recon_loss = 0\n",
    "        for i in range(data.num_graphs):\n",
    "            slice_points = slice_points_list[i].unsqueeze(0) # Add batch dim: [1, N, 2]\n",
    "            slice_z = z[i].unsqueeze(0) # Add batch dim: [1, latent_dim]\n",
    "            \n",
    "            # get_log_likelihood returns a single value for this one slice\n",
    "            log_likelihood = self.generative_core.get_log_likelihood(slice_points, slice_z)\n",
    "            recon_loss -= log_likelihood # We want to MAXIMIZE likelihood, so we MINIMIZE negative likelihood\n",
    "        \n",
    "        recon_loss = recon_loss / data.num_graphs # Average over the batch\n",
    "\n",
    "        # --- 2. KL Divergence Loss ---\n",
    "        # This keeps the latent space smooth and organized\n",
    "        kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        kl_loss = kl_loss / data.num_graphs # Average over the batch\n",
    "\n",
    "        # --- 3. Control Head Loss ---\n",
    "        # Teach the control head to predict the correct bbox and point count\n",
    "        \n",
    "        # Get ground truth values\n",
    "        actual_n = torch.tensor([s.shape[0] for s in slice_points_list], dtype=torch.float32).to(z.device).unsqueeze(1)\n",
    "        \n",
    "        # For bbox, find the min/max of the actual points for each slice\n",
    "        actual_bboxes = []\n",
    "        for s in slice_points_list:\n",
    "            min_coords, _ = torch.min(s, dim=0)\n",
    "            max_coords, _ = torch.max(s, dim=0)\n",
    "            actual_bboxes.append(torch.cat([min_coords, max_coords]))\n",
    "        actual_bboxes = torch.stack(actual_bboxes, dim=0).to(z.device)\n",
    "        \n",
    "        bbox_loss = F.l1_loss(predicted_bbox, actual_bboxes)\n",
    "        n_loss = F.l1_loss(predicted_n, actual_n)\n",
    "        control_loss = bbox_loss + n_loss\n",
    "        \n",
    "        return recon_loss, kl_loss, control_loss\n",
    "\n",
    "print(\"Complete SliceVAE model defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a814815f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 500 epochs on device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/500 [02:59<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     42\u001b[39m total_loss = recon_loss + (kl_weight * kl_loss) + (control_weight * control_loss)\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Backward pass and optimize\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[43mtotal_loss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m optimizer.step()\n\u001b[32m     48\u001b[39m total_recon_loss += recon_loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slice_cfd_prototype/.slice-cfd-proto/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slice_cfd_prototype/.slice-cfd-proto/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slice_cfd_prototype/.slice-cfd-proto/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slice_cfd_prototype/.slice-cfd-proto/lib/python3.12/site-packages/torch/autograd/function.py:307\u001b[39m, in \u001b[36mBackwardCFunction.apply\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    302\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mImplementing both \u001b[39m\u001b[33m'\u001b[39m\u001b[33mbackward\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mvjp\u001b[39m\u001b[33m'\u001b[39m\u001b[33m for a custom \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    303\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFunction is not allowed. You should only implement one \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    304\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mof them.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    305\u001b[39m     )\n\u001b[32m    306\u001b[39m user_fn = vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function.vjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slice_cfd_prototype/.slice-cfd-proto/lib/python3.12/site-packages/torchdiffeq/_impl/adjoint.py:134\u001b[39m, in \u001b[36mOdeintAdjointMethod.backward\u001b[39m\u001b[34m(ctx, *grad_y)\u001b[39m\n\u001b[32m    131\u001b[39m     time_vjps[i] = dLd_cur_t\n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m# Run the augmented system backwards in time.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m aug_state = \u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43maugmented_dynamics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maug_state\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflip\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m=\u001b[49m\u001b[43madjoint_rtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m=\u001b[49m\u001b[43madjoint_atol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43madjoint_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43madjoint_options\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m aug_state = [a[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m aug_state]  \u001b[38;5;66;03m# extract just the t[i - 1] value\u001b[39;00m\n\u001b[32m    140\u001b[39m aug_state[\u001b[32m1\u001b[39m] = y[i - \u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# update to use our forward-pass estimate of the state\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slice_cfd_prototype/.slice-cfd-proto/lib/python3.12/site-packages/torchdiffeq/_impl/odeint.py:80\u001b[39m, in \u001b[36modeint\u001b[39m\u001b[34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[39m\n\u001b[32m     77\u001b[39m solver = SOLVERS[method](func=func, y0=y0, rtol=rtol, atol=atol, **options)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     solution = \u001b[43msolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mintegrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     82\u001b[39m     event_t, solution = solver.integrate_until_event(t[\u001b[32m0\u001b[39m], event_fn)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slice_cfd_prototype/.slice-cfd-proto/lib/python3.12/site-packages/torchdiffeq/_impl/solvers.py:34\u001b[39m, in \u001b[36mAdaptiveStepsizeODESolver.integrate\u001b[39m\u001b[34m(self, t)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mself\u001b[39m._before_integrate(t)\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(t)):\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     solution[i] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_advance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m solution\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slice_cfd_prototype/.slice-cfd-proto/lib/python3.12/site-packages/torchdiffeq/_impl/rk_common.py:246\u001b[39m, in \u001b[36mRKAdaptiveStepsizeODESolver._advance\u001b[39m\u001b[34m(self, next_t)\u001b[39m\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m next_t > \u001b[38;5;28mself\u001b[39m.rk_state.t1:\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m n_steps < \u001b[38;5;28mself\u001b[39m.max_num_steps, \u001b[33m'\u001b[39m\u001b[33mmax_num_steps exceeded (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m>=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m'\u001b[39m.format(n_steps, \u001b[38;5;28mself\u001b[39m.max_num_steps)\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     \u001b[38;5;28mself\u001b[39m.rk_state = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_adaptive_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrk_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m     n_steps += \u001b[32m1\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _interp_evaluate(\u001b[38;5;28mself\u001b[39m.rk_state.interp_coeff, \u001b[38;5;28mself\u001b[39m.rk_state.t0, \u001b[38;5;28mself\u001b[39m.rk_state.t1, next_t)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slice_cfd_prototype/.slice-cfd-proto/lib/python3.12/site-packages/torchdiffeq/_impl/rk_common.py:311\u001b[39m, in \u001b[36mRKAdaptiveStepsizeODESolver._adaptive_step\u001b[39m\u001b[34m(self, rk_state)\u001b[39m\n\u001b[32m    306\u001b[39m         dt = t1 - t0\n\u001b[32m    308\u001b[39m \u001b[38;5;66;03m# Must be arranged as doing all the step_t handling, then all the jump_t handling, in case we\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[38;5;66;03m# trigger both. (i.e. interleaving them would be wrong.)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m y1, f1, y1_error, k = \u001b[43m_runge_kutta_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtableau\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtableau\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[38;5;66;03m# dtypes:\u001b[39;00m\n\u001b[32m    313\u001b[39m \u001b[38;5;66;03m# y1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[32m    314\u001b[39m \u001b[38;5;66;03m# f1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m \u001b[38;5;66;03m#                     Error Ratio                      #\u001b[39;00m\n\u001b[32m    320\u001b[39m \u001b[38;5;66;03m########################################################\u001b[39;00m\n\u001b[32m    321\u001b[39m error_ratio = _compute_error_ratio(y1_error, \u001b[38;5;28mself\u001b[39m.rtol, \u001b[38;5;28mself\u001b[39m.atol, y0, y1, \u001b[38;5;28mself\u001b[39m.norm)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slice_cfd_prototype/.slice-cfd-proto/lib/python3.12/site-packages/torchdiffeq/_impl/rk_common.py:78\u001b[39m, in \u001b[36m_runge_kutta_step\u001b[39m\u001b[34m(func, y0, f0, t0, dt, t1, tableau)\u001b[39m\n\u001b[32m     76\u001b[39m         perturb = Perturb.NONE\n\u001b[32m     77\u001b[39m     yi = y0 + torch.sum(k[..., :i + \u001b[32m1\u001b[39m] * (beta_i * dt), dim=-\u001b[32m1\u001b[39m).view_as(f0)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     f = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mti\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperturb\u001b[49m\u001b[43m=\u001b[49m\u001b[43mperturb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     k = _UncheckedAssign.apply(k, f, (..., i + \u001b[32m1\u001b[39m))\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (tableau.c_sol[-\u001b[32m1\u001b[39m] == \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (tableau.c_sol[:-\u001b[32m1\u001b[39m] == tableau.beta[-\u001b[32m1\u001b[39m]).all()):\n\u001b[32m     82\u001b[39m     \u001b[38;5;66;03m# This property (true for Dormand-Prince) lets us save a few FLOPs.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slice_cfd_prototype/.slice-cfd-proto/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slice_cfd_prototype/.slice-cfd-proto/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slice_cfd_prototype/.slice-cfd-proto/lib/python3.12/site-packages/torchdiffeq/_impl/misc.py:197\u001b[39m, in \u001b[36m_PerturbFunc.forward\u001b[39m\u001b[34m(self, t, y, perturb)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    195\u001b[39m     \u001b[38;5;66;03m# Do nothing.\u001b[39;00m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slice_cfd_prototype/.slice-cfd-proto/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slice_cfd_prototype/.slice-cfd-proto/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slice_cfd_prototype/.slice-cfd-proto/lib/python3.12/site-packages/torchdiffeq/_impl/misc.py:165\u001b[39m, in \u001b[36m_ReverseFunc.forward\u001b[39m\u001b[34m(self, t, y)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, t, y):\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mul * \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slice_cfd_prototype/.slice-cfd-proto/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slice_cfd_prototype/.slice-cfd-proto/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slice_cfd_prototype/.slice-cfd-proto/lib/python3.12/site-packages/torchdiffeq/_impl/misc.py:144\u001b[39m, in \u001b[36m_TupleFunc.forward\u001b[39m\u001b[34m(self, t, y)\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, t, y):\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     f = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_flat_to_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshapes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat([f_.reshape(-\u001b[32m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m f_ \u001b[38;5;129;01min\u001b[39;00m f])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slice_cfd_prototype/.slice-cfd-proto/lib/python3.12/site-packages/torchdiffeq/_impl/adjoint.py:94\u001b[39m, in \u001b[36mOdeintAdjointMethod.backward.<locals>.augmented_dynamics\u001b[39m\u001b[34m(t, y_aug)\u001b[39m\n\u001b[32m     91\u001b[39m     _y = torch.as_strided(y, (), ())  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m     92\u001b[39m     _params = \u001b[38;5;28mtuple\u001b[39m(torch.as_strided(param, (), ()) \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m adjoint_params)  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     vjp_t, vjp_y, *vjp_params = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43madjoint_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43madj_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     97\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# autograd.grad returns None if no gradient, set to zero.\u001b[39;00m\n\u001b[32m    100\u001b[39m vjp_t = torch.zeros_like(t) \u001b[38;5;28;01mif\u001b[39;00m vjp_t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m vjp_t\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slice_cfd_prototype/.slice-cfd-proto/lib/python3.12/site-packages/torch/autograd/__init__.py:496\u001b[39m, in \u001b[36mgrad\u001b[39m\u001b[34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[39m\n\u001b[32m    492\u001b[39m     result = _vmap_internals._vmap(vjp, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, allow_none_pass_through=\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[32m    493\u001b[39m         grad_outputs_\n\u001b[32m    494\u001b[39m     )\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     result = \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[32m    506\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m    507\u001b[39m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[32m    508\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[32m    509\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/slice_cfd_prototype/.slice-cfd-proto/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- 1. Setup Model, Optimizer, and Data ---\n",
    "LATENT_DIM = 128\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Use the 'single_file_dataloader' we created and tested in the previous steps\n",
    "# It loads all slices from our one test car.\n",
    "dataloader = poc_dataloader\n",
    "\n",
    "model = SliceVAE(latent_dim=LATENT_DIM).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "kl_weight = 0.1 # A weight to balance the KL loss against the other losses\n",
    "control_weight = 1.0 # A weight for the bbox and N prediction loss\n",
    "\n",
    "# --- 2. The Training Loop ---\n",
    "NUM_EPOCHS = 500 # For a single car, we can train for more epochs to see clear progress\n",
    "print(f\"Starting training for {NUM_EPOCHS} epochs on device: {DEVICE}\")\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS), desc=\"Epochs\"):\n",
    "    model.train()\n",
    "    \n",
    "    total_recon_loss = 0\n",
    "    total_kl_loss = 0\n",
    "    total_control_loss = 0\n",
    "    \n",
    "    # Since our dataloader contains all slices for one car, one batch is one epoch\n",
    "    for batch in dataloader:\n",
    "        batch = batch.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        mu, log_var, z, predicted_bbox, predicted_n = model(batch)\n",
    "        \n",
    "        # Calculate loss components\n",
    "        recon_loss, kl_loss, control_loss = model.loss_function(\n",
    "            batch, mu, log_var, z, predicted_bbox, predicted_n\n",
    "        )\n",
    "        \n",
    "        # Combine losses with weights\n",
    "        total_loss = recon_loss + (kl_weight * kl_loss) + (control_weight * control_loss)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_recon_loss += recon_loss.item()\n",
    "        total_kl_loss += kl_loss.item()\n",
    "        total_control_loss += control_loss.item()\n",
    "        \n",
    "    # Print progress every 25 epochs\n",
    "    if (epoch + 1) % 25 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | \"\n",
    "              f\"Total Loss: {total_loss.item():.4f} | \"\n",
    "              f\"Recon Loss: {total_recon_loss:.4f} | \"\n",
    "              f\"KL Loss: {total_kl_loss:.4f} | \"\n",
    "              f\"Control Loss: {total_control_loss:.4f}\")\n",
    "\n",
    "print(\"\\nTraining complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372d20bf",
   "metadata": {},
   "source": [
    "### Test and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69488df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. Set model to evaluation mode ---\n",
    "model.eval()\n",
    "\n",
    "# --- 2. Get the same batch of data we trained on ---\n",
    "batch = next(iter(dataloader)).to(DEVICE)\n",
    "original_slices = [data.x for data in batch.to_data_list()]\n",
    "\n",
    "# --- 3. Run the full autoencoder pipeline ---\n",
    "with torch.no_grad():\n",
    "    # Get the latent vector 'mu' (the center of the fuzzy cloud) for reconstruction\n",
    "    mu, log_var = model.encoder(batch)\n",
    "    \n",
    "    # Decode mu to get the scaffolding and the normalized points\n",
    "    predicted_bbox, predicted_n = model.control_head(mu)\n",
    "    \n",
    "    # We use the predicted N to generate a variable number of points for each slice\n",
    "    reconstructed_slices_normalized = []\n",
    "    for i in range(len(mu)):\n",
    "        num_points = int(predicted_n[i].round().item())\n",
    "        z_slice = mu[i].unsqueeze(0)\n",
    "        # Generate points in the [-1, 1] box\n",
    "        points = model.generative_core.generate(z_slice, num_points)\n",
    "        reconstructed_slices_normalized.append(points.squeeze(0))\n",
    "\n",
    "# --- 4. De-normalize the reconstructions ---\n",
    "reconstructed_slices_final = []\n",
    "for i in range(len(reconstructed_slices_normalized)):\n",
    "    points = reconstructed_slices_normalized[i]\n",
    "    bbox = predicted_bbox[i]\n",
    "    min_coords = bbox[:2]\n",
    "    max_coords = bbox[2:4]\n",
    "    \n",
    "    # Stretch the points from [-1, 1] to the predicted bbox\n",
    "    scale = (max_coords - min_coords) / 2.0\n",
    "    center = (max_coords + min_coords) / 2.0\n",
    "    final_points = points * scale + center\n",
    "    reconstructed_slices_final.append(final_points)\n",
    "\n",
    "# --- 5. Visualize the results ---\n",
    "num_to_show = 5\n",
    "fig, axes = plt.subplots(num_to_show, 2, figsize=(8, 12))\n",
    "fig.suptitle(\"Model Reconstruction vs. Original\", fontsize=16)\n",
    "axes[0, 0].set_title(\"Original Slice\")\n",
    "axes[0, 1].set_title(\"Reconstructed Slice\")\n",
    "\n",
    "for i in range(num_to_show):\n",
    "    original = original_slices[i*10].cpu().numpy() # Show every 10th slice\n",
    "    reconstructed = reconstructed_slices_final[i*10].cpu().numpy()\n",
    "    \n",
    "    # Plot original\n",
    "    axes[i, 0].scatter(original[:, 0], original[:, 1], s=1, c='blue')\n",
    "    axes[i, 0].set_aspect('equal', adjustable='box')\n",
    "    axes[i, 0].set_ylabel(f\"Slice {i*10}\")\n",
    "    \n",
    "    # Plot reconstructed\n",
    "    axes[i, 1].scatter(reconstructed[:, 0], reconstructed[:, 1], s=1, c='red')\n",
    "    axes[i, 1].set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".slice-cfd-proto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
